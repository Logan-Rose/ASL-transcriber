{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "\n",
    "# for reproducibility purposes\n",
    "SEED = 123\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this cell to generate the data needed to train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes hand detection output to add bounding rectangles\n",
    "def find_hands(current, width, height):\n",
    "    rect_list = []\n",
    "    hand_classifier = []\n",
    "    center = (0,0)\n",
    "    # iterates through hand tracking data per hand\n",
    "    if current.multi_hand_landmarks:\n",
    "        for index, info in enumerate(current.multi_handedness):\n",
    "            which = info.classification[0].label\n",
    "            hand_classifier.append(which)\n",
    "        for index, hand in enumerate(current.multi_hand_landmarks):\n",
    "            # values from 0 to 1 converted into values corresponding to video size\n",
    "            hand_list = []\n",
    "            for individual in hand.landmark:\n",
    "                hand_list.append((int(individual.x * width), int(individual.y * height), int(individual.z * width)))\n",
    "            # developing bounding box coordinates\n",
    "            x_values = np.array(hand_list)[:, 0]\n",
    "            y_values = np.array(hand_list)[:, 1]\n",
    "            x_min = int(np.min(x_values) - 10)\n",
    "            y_min = int(np.min(y_values) - 10)\n",
    "            x_max = int(np.max(x_values) + 10)\n",
    "            y_max = int(np.max(y_values) + 10)\n",
    "            center = (x_min + (x_max-x_min)//2, y_min + (y_max-y_min)//2)\n",
    "            rect_list.append(((x_min, y_min), (x_max, y_max), (0, 255, 0), hand_classifier[index]))\n",
    "    return rect_list, center\n",
    "def capture():\n",
    "    video = cv.VideoCapture(0, cv.CAP_DSHOW) #captureDevice = camera\n",
    "    running, original = video.read()\n",
    "    h, w, _ = original.shape    \n",
    "    # machine learning algorithm (using mediapipe, via google)\n",
    "    # init_hands = mp.solutions.hands\n",
    "    # hands = init_hands.Hands()\n",
    "    hands = mp.solutions.hands.Hands()\n",
    "    savedFrames = []\n",
    "    # continuous looping\n",
    "    while True:\n",
    "        running, original = video.read()\n",
    "        if not running:\n",
    "            break\n",
    "        # hand processing\n",
    "        track_curr = hands.process(original)\n",
    "        # calculating bounding rectangles\n",
    "        current_rects, center = find_hands(track_curr, w, h)\n",
    "\n",
    "        if current_rects:\n",
    "          if len(current_rects) > 1:\n",
    "            print('Please use only one hand')\n",
    "          else:\n",
    "            current_rect = current_rects[0]\n",
    "            left = current_rect[0][0]\n",
    "            right = current_rect[1][0]\n",
    "            top = current_rect[0][1]\n",
    "            bottom = current_rect[1][1]\n",
    "            hand_width = right - left\n",
    "            hand_height = bottom-top\n",
    "            square_top_left = (center[0]-75,center[1]-75)\n",
    "            square_bottom_right = (center[0]+75,center[1]+75)\n",
    "\n",
    "            red = (0,0,255)\n",
    "            green = (0,255,0)\n",
    "            if hand_width <= 150 and hand_height <= 150:\n",
    "              if top > 0 and left > 0 and bottom > 0 and right > 0:\n",
    "                # cv.rectangle(original, current_rect[0], current_rect[1], green, 1)\n",
    "                cv.rectangle(original,square_top_left ,square_bottom_right , green,1)\n",
    "                crop = original[center[1]-75:center[1]+75,center[0]-75:center[0]+75]   \n",
    "                savedFrames.append(crop)\n",
    "              \n",
    "                # cv.circle(original, center, 10, 2, 2)\n",
    "            else:\n",
    "              cv.rectangle(original, current_rect[0], current_rect[1], red, 2)\n",
    "              cv.rectangle(original,square_top_left ,square_bottom_right , red,2)\n",
    "              print(\"You're too close! Back up!\")\n",
    "        cv.imshow(\"Video Feed\", original)\n",
    "        k = cv.waitKey(1) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "    cv.destroyAllWindows()\n",
    "    video.release()\n",
    "    return savedFrames\n",
    "frames = capture()\n",
    "\n",
    "# Make sure to update the directory each time you run this script!\n",
    "for i, frame in enumerate(frames):\n",
    "  frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "  cv.imwrite(f'./custom_dataset/a/{i}.jpg', frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split to test data folder\n",
    "Because the imagedatagenerator only splits between train nad validation datasets, this automatically creates a test data directory to copy 20 random images from each class into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the test data\n",
    "import os\n",
    "import shutil\n",
    "from random import randrange\n",
    "\n",
    "test_data_dir = './test_data'\n",
    "os.mkdir(test_data_dir)\n",
    "for c in classes:\n",
    "  os.mkdir(f'{test_data_dir}/{c}')\n",
    "\n",
    "train_data_dir = './custom_dataset'\n",
    "test_data_dir = './test_data'\n",
    "\n",
    "for c in classes:\n",
    "  current = f'{train_data_dir}/{c}'\n",
    "  for i in range(20):\n",
    "    arr = os.listdir(current)\n",
    "    file = arr[randrange(len(arr))]\n",
    "    shutil.copyfile(f'{train_data_dir}/{c}/{file}', f'{test_data_dir}/{c}/{file}')\n",
    "    os.remove(f'{train_data_dir}/{c}/{file}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
