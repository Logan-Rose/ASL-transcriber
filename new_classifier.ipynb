{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "import shutil\n",
    "import os\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# for reproducibility purposes\n",
    "SEED = 123\n",
    "tf.random.set_seed(SEED)\n",
    "classes=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','0','12','3','4','5','6','7','8','9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1452 images belonging to 35 classes.\n",
      "Found 363 images belonging to 35 classes.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20.0,\n",
    "    width_shift_range=20.0,\n",
    "    height_shift_range=20.0,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=.1,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    # vertical_flip=True,\n",
    "    validation_split=0.2    \n",
    "    \n",
    ")\n",
    "\n",
    "train_generator = img_generator.flow_from_directory(\n",
    "  './asl_dataset',\n",
    "  target_size=(48,48),\n",
    "  color_mode='grayscale',\n",
    "  classes=classes,\n",
    "  class_mode='categorical',\n",
    "  seed=SEED,\n",
    "  shuffle=False,\n",
    "  subset='training'\n",
    ")\n",
    "\n",
    "val_generator = img_generator.flow_from_directory(\n",
    "  './asl_dataset',\n",
    "  target_size=(48,48),\n",
    "  color_mode='grayscale',\n",
    "  classes=classes,\n",
    "  class_mode='categorical',\n",
    "  seed=SEED,\n",
    "  shuffle=False,\n",
    "  subset='validation'\n",
    ")\n",
    "\n",
    "for i, image in enumerate(val_generator):\n",
    "  if i == 5:\n",
    "    plt.imshow(image[0][1], cmap = 'gray')\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Logan\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 48, 48, 1)]       0         \n",
      "                                                                 \n",
      " layer1 (Conv2D)             (None, 47, 47, 16)        80        \n",
      "                                                                 \n",
      " layer2 (MaxPooling2D)       (None, 23, 23, 16)        0         \n",
      "                                                                 \n",
      " layer3 (Flatten)            (None, 8464)              0         \n",
      "                                                                 \n",
      " layer4 (Dense)              (None, 64)                541760    \n",
      "                                                                 \n",
      " layer5 (Dense)              (None, 128)               8320      \n",
      "                                                                 \n",
      " layer6 (Dense)              (None, 128)               16512     \n",
      "                                                                 \n",
      " symbol (Dense)              (None, 35)                4515      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 571,187\n",
      "Trainable params: 571,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "46/46 [==============================] - 5s 97ms/step - loss: 9.0245 - top_k_categorical_accuracy: 0.1522 - val_loss: 1.7928 - val_top_k_categorical_accuracy: 0.1901 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "46/46 [==============================] - 4s 93ms/step - loss: 1.7692 - top_k_categorical_accuracy: 0.1377 - val_loss: 1.7725 - val_top_k_categorical_accuracy: 0.1901 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "46/46 [==============================] - 4s 93ms/step - loss: 1.7615 - top_k_categorical_accuracy: 0.1474 - val_loss: 1.7518 - val_top_k_categorical_accuracy: 0.1956 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "46/46 [==============================] - 4s 94ms/step - loss: 1.7485 - top_k_categorical_accuracy: 0.1674 - val_loss: 1.7383 - val_top_k_categorical_accuracy: 0.1846 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "46/46 [==============================] - 4s 92ms/step - loss: 1.7318 - top_k_categorical_accuracy: 0.1612 - val_loss: 1.7183 - val_top_k_categorical_accuracy: 0.1763 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "46/46 [==============================] - 4s 94ms/step - loss: 1.7091 - top_k_categorical_accuracy: 0.1921 - val_loss: 1.6889 - val_top_k_categorical_accuracy: 0.1983 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "46/46 [==============================] - 4s 92ms/step - loss: 1.6915 - top_k_categorical_accuracy: 0.1763 - val_loss: 1.6742 - val_top_k_categorical_accuracy: 0.1956 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "46/46 [==============================] - 4s 94ms/step - loss: 1.6739 - top_k_categorical_accuracy: 0.1660 - val_loss: 1.6582 - val_top_k_categorical_accuracy: 0.1956 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "46/46 [==============================] - 4s 92ms/step - loss: 1.6591 - top_k_categorical_accuracy: 0.1515 - val_loss: 1.6471 - val_top_k_categorical_accuracy: 0.1956 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "46/46 [==============================] - 4s 94ms/step - loss: 1.6508 - top_k_categorical_accuracy: 0.1901 - val_loss: 1.6361 - val_top_k_categorical_accuracy: 0.2121 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "46/46 [==============================] - 4s 92ms/step - loss: 1.6467 - top_k_categorical_accuracy: 0.1481 - val_loss: 1.6399 - val_top_k_categorical_accuracy: 0.1928 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "46/46 [==============================] - 4s 93ms/step - loss: 1.6452 - top_k_categorical_accuracy: 0.1398 - val_loss: 1.6201 - val_top_k_categorical_accuracy: 0.2121 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "46/46 [==============================] - 4s 93ms/step - loss: 1.6393 - top_k_categorical_accuracy: 0.1253 - val_loss: 1.6192 - val_top_k_categorical_accuracy: 0.2149 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "46/46 [==============================] - 4s 93ms/step - loss: 1.6378 - top_k_categorical_accuracy: 0.1612 - val_loss: 1.6101 - val_top_k_categorical_accuracy: 0.2397 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "46/46 [==============================] - 4s 93ms/step - loss: 1.6398 - top_k_categorical_accuracy: 0.1584 - val_loss: 1.6272 - val_top_k_categorical_accuracy: 0.2066 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6e102c3ca0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = keras.Input(shape=(48, 48, 1))\n",
    "layer1 = tf.keras.layers.Conv2D(16, (2,2), activation= 'relu', name=\"layer1\")\n",
    "layer2 = tf.keras.layers.MaxPool2D(2,2, name=\"layer2\")\n",
    "layer3 = tf.keras.layers.Flatten(name=\"layer3\")\n",
    "layer4 = tf.keras.layers.Dense(64, activation='relu', name='layer4')\n",
    "layer5 = tf.keras.layers.Dense(128, activation='relu', name='layer5')\n",
    "layer6 = tf.keras.layers.Dense(128, activation='relu', name='layer6')\n",
    "\n",
    "output =  tf.keras.layers.Dense(len(classes), activation='sigmoid', name='symbol')\n",
    "\n",
    "network = output(layer6(layer5(layer4(layer3(layer2(layer1(input)))))))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "model = tf.keras.Model(inputs=input, outputs=network, name=\"Logan\")\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              loss_weights=[0.5],\n",
    "              metrics=[tf.keras.metrics.top_k_categorical_accuracy],\n",
    "              )\n",
    "\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "# checkpoints = keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=check_dir,\n",
    "#     monitor='val_loss',\n",
    "#     save_best_only=True,\n",
    "#     save_weights_only=False\n",
    "# )\n",
    "# tensorboard = keras.callbacks.TensorBoard(\n",
    "#     log_dir=tboard_dir\n",
    "# )\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stop, reduce_lr]\n",
    "\n",
    "# fit the model with training and validation generators\n",
    "# In addition please specify the following arguments\n",
    "# steps_per_epoch=len(df_train)/batch_size\n",
    "# validation_steps=len(df_val)/batch_size\n",
    "# (5)\n",
    "print(model.summary())\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False)\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        epochs=15,\n",
    "        validation_data=val_generator,\n",
    "        batch_size=8, \n",
    "        callbacks=callbacks,\n",
    "        # steps_per_epoch=len(train)/batch_size,\n",
    "        # validation_steps=len(val)/batch_size\n",
    "        )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "367e97bd1bb993270875333a5c0c0ed703268d8b20e00e99d22f213f8fc7c5a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
